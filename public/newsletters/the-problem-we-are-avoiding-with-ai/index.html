
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Problem We&#x27;re Avoiding with AI | CYBORG_ Newsletter</title>
    <link rel="stylesheet" href="/static/css/styles.css">

    <!-- FONTS -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Roboto+Flex:opsz,wght@8..144,100..1000&display=swap" rel="stylesheet">
    <!-- /FONTS -->

    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Upgrade your humanity.">
    <meta name="twitter:description" content="An exploration of technology and systems and how they interact, dominate, or support our humanity.">
    <meta name="twitter:site" content="@NotDefinedTech">
    <meta name="twitter:image" content="https://cyborgnewsletter.com/static/social/cyborg-subscribe-gen.jpg">
    <meta name="twitter:creator" content="@NotDefinedTech">
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Upgrade your humanity.">
    <meta property="og:description" content="An exploration of technology and systems and how they interact, dominate, or support our humanity.">
    <meta property="og:url" content="https://cyborgnewsletter.com/">
    <meta property="og:site_name" content="CYBORG_ Newsletter">
    <meta property="og:image" content="https://cyborgnewsletter.com/static/social/cyborg-subscribe-gen.jpg">
    <meta property="og:image:secure_url" content="https://cyborgnewsletter.com/static/social/cyborg-subscribe-gen.jpg">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    
    <link rel="icon" href="/static/images/brand/favicon/cyborg.ico" sizes="32x32">
    
    
</head>
<body class="article">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-JGP9HHYEJ7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-JGP9HHYEJ7');
    </script>

    
        <nav id="header">
    <a href="/">CYBORG_</a>

    <input type="checkbox" id="nav-toggle" class="nav-toggle">
    <label for="nav-toggle" class="nav-toggle-button">
        <span></span>
    </label>
    <div class="menu">
        <div class="navigation">
            <ul>
                <li>
                    <a href="/newsletters/" class="">Newsletters</a>
                </li>
                <li>
                    <a href="/topics/">Topics</a>
                </li>
            </ul>
        </div>
        <div class="action">
            <ul>
                <li>
                    <a href="/subscribe/" class="btn btn-primary">Subscribe <span class="cta-arrow"></span></a>
                </li>
            </ul>
        </div>
    </div>
</nav>
    
    
    <main id="main">
        
<ul class="breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
    <li itemprop="itemListElement" itemscope
    itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="/"><span itemprop="name">Home</span></a>&nbsp;/&nbsp;
        <meta itemprop="position" content="1" />
    </li>
    
    <li itemprop="itemListElement" itemscope
    itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="/newsletters/"><span itemprop="name">Newsletters</span></a>&nbsp;/&nbsp;
        <meta itemprop="position" content="2" />
    </li>
    
    The Problem We&#x27;re Avoiding with AI
</ul>

<article class="article" itemscope itemtype="https://schema.org/Article">
    <meta itemprop="name" content="">
    
    <meta itemprop="description" content="Forget killer robots. There&#x27;s something much more concerning in the quiet, everyday problems AI presents that society prefers to ignore—until it&#x27;s too late.">
    
    <meta itemprop="datePublished" content="2024-03-26T13:01:37Z">
    <meta itemprop="author" content="Jess Brown">


    <div class="grid-article">
        <header>

            <div itemprop="isPartOf" itemscope itemtype="https://schema.org/PublicationIssue" itemid="#issue">
                <div itemscope itemtype="https://schema.org/Periodical" itemid="#periodical">
                    <meta itemprop="name" content="CYBORG_ Newsletter">
                    <meta itemprop="id" href="https://cyborgnewsletter.com/#periodical">
                </div>
                <meta itemprop="copyrightHolder" content="Not Defined LLC">
                <div itemprop="isPartOf" itemscope itemtype="https://schema.org/PublicationVolume">
                    <link itemprop="isPartOf" href="https://cyborgnewsletter.com/#periodical" />
                    <meta itemprop="volumeNumber" content="12">
                </div>
            </div>
            
            <h1 itemprop="headline">The Problem We&#x27;re Avoiding with AI</h1>
        </header>
        
        <div class="article-content" itemprop="articleBody">
            <p>We, as a species, have been thrown into exceptionally dangerous circumstances with the new breed of AI. I've been waiting to write this particular email on this particular topic, because I found myself waffling between opinions and false understanding.</p>
<p>I've been examining AI from philosophical, technical, political, and even science-fictional standpoints. I don't have the answers yet—no one really does. But I have stumbled upon some concerning and critical topics that aren't prevalent in the AI discussion—at least, not in the general population.</p>
<p>AI has been something I've been comfortable with, something I've sought after, and something I've advocated for up until recently. To set the stage, let's quickly discuss what AI <em>actually</em> is and what the real concerns are that we should be taking seriously.</p>
<h2>Statistics</h2>
<p>AI is not <em>actual</em> intelligence, it is <em>artificial</em> intelligence. It is based in statistics. It <em>predicts</em> what will best accomplish its task, whether that's responding to your question or creating imagery from your prompts.</p>
<p>This is absolutely fundamental to understand before we dive into the ramifications of AI. </p>
<p>It is certainly not sentient. We can give space for that possibility in the future, but that argument is a clever distraction.</p>
<h2>HADD</h2>
<p>Humans have a bias. It's built-in and it's exceptionally powerful and persuasive to us. Our brains are a Hyperactive Agency Detection Device (HADD). There are theories that our human inclination to connect events that happen around us to supernatural beings is largely because of HADD.</p>
<p>We hear a twig snap in the forest near us, but we know we're alone—was it a spirit? Was it evil? A monster? </p>
<p>Haunted houses or spaces where &quot;things happen&quot; are surely evidence for ghosts. </p>
<p>Calamities fall upon some city or (even worse) some ethnic group and we say, &quot;Surely, it is God's punishment for their wickedness.&quot;</p>
<p>All of this is exasperated because of our biological wiring. We can't help but personify the inanimate, breathe life into containers where there is none, project our feelings and thoughts onto creatures or even people that do not share those same feelings and thoughts.</p>
<p>We see a response from ChatGPT and it <em>feels</em> like it is talking to us—like it's human. It's using our language—and I don't just mean it's using &quot;English&quot; or &quot;Spanish,&quot; it uses phrases that express emotions, &quot;Certainly! I can help you with that...&quot; or &quot;I'm sorry for the confusion...&quot; or &quot;You're right...&quot;</p>
<p>This will continue to <em>feel</em> more and more like you're interacting with a being. Something with feelings and intelligence and maybe even desires. </p>
<p>Remember, this is just a prediction model. What is the most likely, best response to the prompt given? That's AI.</p>
<p>Not all of this is HADD theory, but anecdotal experience tells me that we, humans, do a very good job at distracting ourselves from real, root problems because it's so easy to dehumanize actual people and humanize non-humans. </p>
<p>I'm not arguing this HADD-bias is always bad, but without awareness, we can't move forward.</p>
<h2>The Real Problem with AI</h2>
<p>People are always—have always been—the real problem with AI.</p>
<p>We are playing with the next nukes. And we're doing so without responsibility, without wisdom, without restraint, and without any real safety measures.</p>
<img src="https://embed.filekitcdn.com/e/iDKTPNXrEJsYXUT7GCu1J3/3WhB4hoFKYf6Y2r58E1er8" alt="Your scientists were so preoccupied with whether or not they could...they didn't stop to think if they should.">
<p>Tristan Harris puts it perfectly: &quot;You can't have the power of gods without the love, prudence, and wisdom of gods.&quot; (He may have been referencing Daniel Schmachtenberger, I'm not sure who's the original source.)</p>
<h3>Love</h3>
<p>How is it that we as humans have immense capacity to love; have religions whose underlying basis is love; have an inclination to love and still end up drawing borders, starting wars, greedily exploiting, creating &quot;others&quot; or &quot;monsters&quot; of groups of people?</p>
<p>How do we truly instill &quot;love for each human&quot; as a vital, indispensable core value in our societies?</p>
<p>Without that kind of love, AI will be used to destroy what we've built and cause suffering at a scale we have not yet seen.</p>
<h3>Prudence</h3>
<p>Caution. In what world do business leaders choose caution over profits? Probably the world that survives. </p>
<p>The problem is that we created a race, and when a race is started, no one is incentivized to stop racing. At best, we have the fallacious attitude, &quot;Better us than them.&quot; Better we create it first, 'cause the other guy is not going to be as safe, smart, careful as we are.</p>
<p>In a traditional system, a young person who has tapped into some massive amount of power would have an elder come by and cut them down a bit: &quot;Slow down, you're not ready, you need to wait.&quot; </p>
<p>We have no elders in the AI space. No one tempering the possibility with patience, caution, respect for the danger. Instead, the environment of tech companies is: &quot;Move, ship, go.&quot; Get it done yesterday and always be first to market. <a href="https://www.humanetech.com/podcast/can-myth-teach-us-anything-about-the-race-to-build-artificial-general-intelligence-with-josh-schrei">Josh Schrei</a> </p>
<p>Policies and regulation might be able to help here, but self-restraint and big-picture thinking will become critical skills for everyone to develop and encourage. It's no longer acceptable to run, unchecked, unaccountable in the tech space.</p>
<h3>Wisdom</h3>
<p>This needs to become the pursuit <em>before</em> developing AI further. <em>Before</em> we unleash irrevocable power to anyone without wisdom. Again, I'll pull what Tristan Harris has said: &quot;If 99% of people want good for the world and 1% doesn't, it's still a broken world.&quot;</p>
<p>The problem with wisdom is the same it has always been: it's hard.</p>
<p>When faced with a path full of hardship, self-sacrifice, obstacles, delayed rewards and a path that is easy, clear, free, and instantly gratifying, it's all too easy to choose that path of least resistance. Especially when you have not developed the wisdom to pursue wisdom. And we're back in the spiral.</p>
<h2>What do we do?</h2>
<p>Taking AI seriously is the first step. It's easy to pass off AI as a silly gimmick or something that &quot;is coming for our jobs.&quot; AI unlocks doors we thought were securely closed—thinking of past topics we've discussed here, like content-based verification: your voice, your likeness in photo or video, details about your life.</p>
<p>Remember that we're not interacting with a being. We cannot allow young people to develop relationships with AI. They must know that it is an illusion, it cannot be fully trusted to provide safe, wise, or accurate answers or advice.</p>
<p>Josh Comeau put it well that AI sounds 100% confident, but is only 80% accurate—making it hard for us to not believe it. When AI appears so smart, so confident, how could we possibly be able to discern its errors?</p>
<p>We need to place pressure on government to create regulations, to fight against unchecked powers with deep pockets.</p>
<p>I highly recommend listening to the podcast, &quot;Your Undivided Attention.&quot; It started with the &quot;social dilemma,&quot; taking on the dangers of social media and the addictive nature of what we've built. As of 2023, they've expanded the discussion to the &quot;AI dilemma&quot; and provide lots of important insights into dangers and potential solutions:
https://www.humanetech.com/podcast</p>
        </div>

        <aside id="article-outline">
            <h2>Outline</h2>
            <nav aria-label="Outline">
                <ul id="article-outline-content"></ul>
            </nav>
            <script>
            const outline = document.getElementById('article-outline-content');
            const content = document.querySelector('.article-content');
            
            function generateOutline(contentElement) {
              const headings = contentElement.querySelectorAll('h1, h2, h3, h4, h5, h6');
              if(headings.length > 0){
                    headings.forEach(heading => {
                        const outlineItem = document.createElement('li');
                        const anchor = document.createElement('a');
                        anchor.href = '#' + heading.id; // If headings have IDs
                        anchor.textContent = heading.textContent;
                        outlineItem.appendChild(anchor);
                        outlineItem.classList.add(heading.tagName.toLowerCase()); 
        
                        anchor.addEventListener('click', (event) => {
                            event.preventDefault();
                            heading.scrollIntoView({ behavior: 'smooth' });
                        });
        
                        outline.appendChild(outlineItem);
                    });
                }
                else {
                    const article = document.getElementById("blog-article");
                    const sidebar = document.getElementById("outline-sidebar");
                    article.classList.remove("justify-content-between");
                    article.classList.add("justify-content-center");
                    sidebar.classList.add("d-none");
                }
            }
            generateOutline(content);
            </script>
        </aside>
    </div>
</article>



    </main>
    
    
    <footer>
        <div class="copyright">
            &copy; 2025 Not Defined LLC. All rights reserved.
        </div>
        <div class="policies">
            <a href="/policies/artificial-intelligence/">AI Policy</a>
        </div>
        
    </footer>
    

    


    <script src="/static/js/scripts.js" defer></script>

</body>
</html>